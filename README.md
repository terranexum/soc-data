# soc-data
This project was done at an internship at [TerraNexum](https://www.terranexum.com/)
## Libraries and datasets used
### Data
* [1.6 million labeled tweets](https://www.kaggle.com/datasets/kazanova/sentiment140)
* Self-labeled training/testing data - See [Twitter.ipynb](https://github.com/terranexum/soc-data/blob/main/notebooks/Twitter.ipynb)
### Libraries
*
*
*
## Overview
The primary objective is to develop a sentiment analysis model that can accurately classify tweets based on their sentiment. 
The notebooks are structured as follows:

1.	Retrieve [(Twitter.ipynb)](https://github.com/terranexum/soc-data/blob/main/notebooks/Twitter.ipynb): Connect to the Twitter API to retreive tweets
    
2.	Manual Classification [(label.ipynb)](https://github.com/terranexum/soc-data/blob/main/notebooks/label.ipynb): This notebook allows users to manually classify the retrieved tweets into different sentiment categories.

3.	Sentiment Analysis Model - large training data [(new data classifying large.ipynb)](https://github.com/terranexum/soc-data/blob/main/notebooks/new%20data%20classifying%20large.ipynb): Train and evaluate a model trained off of 1.6 million tweets

4. Sentiment Analysis Model - small training data [(new_Data classifying small.ipynb)](https://github.com/terranexum/soc-data/blob/main/notebooks/new_Data%20classifying%20small.ipynb): Similar to the former, train and evaluate model trained off of only 100 tweets

## Twitter.ipynb
> NOTE: this code requires "Basic" teir access to the Twitter (fka X) API as of July 2024

Using Tweepy and the Twitter API, 

## label.ipynb

## new data classifying large.ipynb

## new_Data classifying small.ipynb

